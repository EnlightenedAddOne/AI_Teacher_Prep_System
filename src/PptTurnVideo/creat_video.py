# åˆæˆè§†é¢‘
import os
import re
import time

import edge_tts
import numpy as np
from moviepy import AudioFileClip, ImageSequenceClip, concatenate_audioclips

# å£°çº¿æ˜ å°„å­—å…¸
VOICE_TYPE_MAPPING = {
    "å¹´è½»ç”·å£°": "zh-CN-YunxiNeural",
    "æ¸©æš–å¥³å£°": "zh-CN-YunxiaNeural",
    "æ’­éŸ³ç”·å£°": "zh-CN-YunyangNeural",
    "ç”œç¾å¥³å£°": "zh-CN-XiaoxiaoNeural",
    "æ´»æ³¼å¥³å£°": "zh-CN-XiaoyiNeural"
}


def get_edge_voice_type(voice_type: str) -> str:
    """
    è·å–Edge TTSä½¿ç”¨çš„å£°çº¿ä»£ç 
    :param voice_type: ä¸­æ–‡å£°çº¿åç§°
    :return: Edge TTSå£°çº¿ä»£ç 
    :raises ValueError: å¦‚æœå£°çº¿ç±»å‹ä¸æ”¯æŒ
    """
    if voice_type not in VOICE_TYPE_MAPPING:
        valid_voices = list(VOICE_TYPE_MAPPING.keys())
        raise ValueError(f"ä¸æ”¯æŒçš„å£°çº¿ç±»å‹ã€‚æ”¯æŒçš„å£°çº¿ç±»å‹: {', '.join(valid_voices)}")
    return VOICE_TYPE_MAPPING[voice_type]


async def generate_audio_edge(text, output_file, voice='å¹´è½»ç”·å£°'):
    """
    ä½¿ç”¨Edge TTSç”ŸæˆéŸ³é¢‘æ–‡ä»¶
    :param text: è¦è½¬æ¢çš„æ–‡æœ¬
    :param output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    :param voice: ä¸­æ–‡å£°çº¿åç§°
    :return: æ˜¯å¦æˆåŠŸ
    """
    try:
        edge_voice = get_edge_voice_type(voice)
        communicate = edge_tts.Communicate(
            text=text,
            voice=edge_voice,
            rate="+5%",  # è¯­é€Ÿè°ƒæ•´(-50% ~ +100%)
            volume="+0%"  # éŸ³é‡è°ƒæ•´(-50% ~ +50%)
        )
        await communicate.save(output_file)
        return True
    except Exception as e:
        print(f"âš ï¸ è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
        return False


def create_silent_audio(duration, output_file):
    """ç”ŸæˆæŒ‡å®šæ—¶é•¿çš„é™éŸ³éŸ³é¢‘æ–‡ä»¶"""
    # åˆ›å»ºä¸€ä¸ªæŒç»­æ—¶é—´ä¸ºdurationç§’çš„é™éŸ³éŸ³é¢‘æ•°ç»„
    sample_rate = 44100
    np.zeros(int(duration * sample_rate))

    # ä½¿ç”¨ moviepy åˆ›å»ºéŸ³é¢‘å‰ªè¾‘
    audio = ImageSequenceClip([np.zeros((1, 1, 3))], fps=1).set_duration(duration)
    audio = audio.set_audio(None)  # ç¡®ä¿æ²¡æœ‰éŸ³é¢‘

    # ä¿å­˜ä¸ºéŸ³é¢‘æ–‡ä»¶
    audio.write_audiofile(output_file, fps=sample_rate)
    return AudioFileClip(output_file)


async def generate_audio_files(slide_texts, output_folder, voice_type='å¹´è½»ç”·å£°'):
    """
    ç”Ÿæˆæ‰€æœ‰éŸ³é¢‘æ–‡ä»¶ï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰
    :param slide_texts: å¹»ç¯ç‰‡æ–‡æœ¬åˆ—è¡¨
    :param output_folder: è¾“å‡ºæ–‡ä»¶å¤¹
    :param voice_type: ä¸­æ–‡å£°çº¿åç§°
    :return: éŸ³é¢‘ç‰‡æ®µåˆ—è¡¨
    """
    audio_clips = []
    total = len(slide_texts)
    start_time = time.time()
    failed = 0  # å¤±è´¥è®¡æ•°å™¨

    print(f"ğŸ™ï¸ å¼€å§‹ç”ŸæˆéŸ³é¢‘ï¼ˆå…±{total}æ®µï¼‰")
    print(f"ğŸ¤ ä½¿ç”¨å£°çº¿: {voice_type}")

    for idx, text in enumerate(slide_texts):
        # è¿›åº¦æ˜¾ç¤º
        progress = f"[{idx + 1}/{total}]".ljust(8)
        percent = (idx + 1) / total * 100
        print(f"\n{progress} ğŸ“Œ ç¬¬{idx + 1}æ®µéŸ³é¢‘ç”Ÿæˆä¸­ï¼ˆ{percent:.1f}%ï¼‰...")

        if not text.strip():
            text = "æ­¤å¹»ç¯ç‰‡æ— å¤‡æ³¨å†…å®¹"

        audio_file = os.path.join(output_folder, f"audio_{idx}.mp3")

        # å¸¦é‡è¯•æœºåˆ¶çš„ç”Ÿæˆ
        success = False
        for retry in range(3):
            try:
                print(f"   ğŸ”„ å°è¯•ç¬¬{retry + 1}æ¬¡ç”Ÿæˆ...")
                success = await generate_audio_edge(text, audio_file, voice=voice_type)
                if success:
                    print(f"   âœ… ç¬¬{retry + 1}æ¬¡å°è¯•æˆåŠŸ")
                    break
            except Exception as e:
                print(f"   âŒ ç¬¬{retry + 1}æ¬¡å°è¯•å¤±è´¥ï¼š{str(e)}")

        # å¤±è´¥å¤„ç†
        if not success:
            failed += 1
            print(f"   âš ï¸ æœ€ç»ˆç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é™éŸ³æ›¿ä»£")
            # ä½¿ç”¨5ç§’çš„é™éŸ³éŸ³é¢‘æ›¿ä»£
            audio_clips.append(create_silent_audio(5, audio_file))
        else:
            audio_clips.append(AudioFileClip(audio_file))

    # ç”Ÿæˆç»“æœç»Ÿè®¡
    time_cost = time.time() - start_time
    print(f"\nğŸ‰ éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼å…±{total}æ®µ")
    print(f"â±ï¸ æ€»è€—æ—¶ï¼š{time_cost:.1f}ç§’")
    print(f"âœ… æˆåŠŸç‡ï¼š{(total - failed) / total * 100:.1f}%")

    return audio_clips


def create_video_from_images(image_paths, audio_clips, output_video_path):
    if not image_paths:
        raise ValueError("No image files found in the specified folder.")

    durations = [audio.duration for audio in audio_clips]

    # ç¡®ä¿å›¾ç‰‡æ•°é‡ä¸éŸ³é¢‘æ•°é‡åŒ¹é…
    if len(image_paths) != len(durations):
        raise ValueError(f"Mismatch between number of images ({len(image_paths)}) and audio clips ({len(durations)}).")

    # åˆ›å»ºå›¾ç‰‡åºåˆ—å‰ªè¾‘
    clip = ImageSequenceClip(image_paths, durations=durations)

    # åˆå¹¶æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ
    final_audio = concatenate_audioclips(audio_clips)

    # å°†å›¾ç‰‡åºåˆ—å‰ªè¾‘è½¬æ¢ä¸ºè§†é¢‘å‰ªè¾‘å¹¶æ·»åŠ éŸ³é¢‘
    final_clip = clip.with_audio(final_audio)

    # è¾“å‡ºè§†é¢‘
    final_clip.write_videofile(output_video_path, codec='libx264')


# è‡ªç„¶æ’åºå‡½æ•°ï¼ˆå¤„ç†çº¯æ•°å­—æ–‡ä»¶åï¼‰
def natural_sort_key(file_path):
    """æå–æ–‡ä»¶åä¸­çš„æ•°å­—è¿›è¡Œæ’åº"""
    filename = os.path.basename(file_path)
    numbers = re.findall(r'\d+', filename)
    return int(numbers[0]) if numbers else filename
